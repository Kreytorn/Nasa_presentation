{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyO2hYoE4X90tt+OFB5uC3Iw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ItfrJgeiiSQE"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"2xGvcEDhiVkM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-oWyPmHQiVmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ae_3RUgiiVpT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SEIUBSFIiVrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jh7wWB9ZiVt4","executionInfo":{"status":"ok","timestamp":1759575164982,"user_tz":-180,"elapsed":28489,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"0fee6bab-08bd-4884-a687-611dd7519e6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db881d04","executionInfo":{"status":"ok","timestamp":1759575167222,"user_tz":-180,"elapsed":2239,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"1d41cd5d-6799-45e6-8c67-3d89384f9923"},"source":["\n","# Set the path to the 'RADIAL' folder in your Drive\n","main_path = '/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity/RADIAL'\n","\n","# Verify the path exists\n","if not os.path.exists(main_path):\n","    print(f\"Error: The folder '{main_path}' does not exist. Please check the folder name and location in your Google Drive.\")\n","else:\n","    print(f\"Main path set to: {main_path}\")\n","\n","# You can now use 'main_path' to access files and folders within the RADIAL folder"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Main path set to: /content/drive/MyDrive/nasa_exoplanet/RADIAL\n"]}]},{"cell_type":"code","source":["# === Exoplanet RV: download + prep + balanced-train (RADIAL + HARPS) ===\n","# - Downloads into /content/drive/MyDrive/nasa_exoplanet/\n","# - Reads RADIAL .tbl with IPAC parser (fixes the tiny-positives issue)\n","# - Builds tidy series: time, rv, rv_err, star_id, source, label\n","# - Extracts per-star features (periodogram peaks + stats)\n","# - Stratified 90/10 split by star\n","# - Balanced training (undersample negatives to match positives) + LightGBM\n","# - Saves artifacts to processed/\n","\n","import os, re, io, gzip, time, warnings, sys, subprocess\n","from pathlib import Path\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","def pip_install(pkgs):\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n","\n","# deps\n","try:\n","    import requests, pandas as pd, numpy as np\n","except:\n","    pip_install([\"requests\",\"pandas\",\"numpy\"])\n","    import requests, pandas as pd, numpy as np\n","\n","try:\n","    from astropy.io import ascii as astro_ascii\n","    from astropy.timeseries import LombScargle\n","except:\n","    pip_install([\"astropy\"])\n","    from astropy.io import ascii as astro_ascii\n","    from astropy.timeseries import LombScargle\n","\n","try:\n","    import lightgbm as lgb\n","except:\n","    pip_install([\"lightgbm\"])\n","    import lightgbm as lgb\n","\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, precision_recall_curve\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# ====================== CONFIG ======================\n","BASE_DIR   = Path(\"/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity\")\n","RADIAL_DIR = BASE_DIR / \"RADIAL_raw\"\n","HARPS_DIR  = BASE_DIR / \"HARPS_raw\"\n","PROC_DIR   = BASE_DIR / \"processed\"\n","for d in (PROC_DIR, RADIAL_DIR, HARPS_DIR): d.mkdir(parents=True, exist_ok=True)\n","\n","# NASA Exoplanet Archive endpoints\n","WGET_RADIAL_URL = \"https://exoplanetarchive.ipac.caltech.edu/bulk_data_download/wget_RADIAL.bat\"\n","CONFIRMED_HOSTS_CSV = (\n","    \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync?\"\n","    \"query=select+distinct+hostname+from+pscomppars&format=csv\"\n",")\n","\n","# HARPS rvbank mirrors (Trifonov+2020 SERVAL)\n","HARPS_URLS = [\n","    \"https://cdsarc.cds.unistra.fr/ftp/J/A+A/636/A74/rvbank.dat.gz\",\n","    \"https://cdsarc.u-strasbg.fr/ftp/J/A+A/636/A74/rvbank.dat.gz\",\n","    \"https://cdsarc.cds.unistra.fr/ftp/J/A+A/636/A74/rvbank.dat\",\n","]\n","\n","# knobs\n","MAX_WORKERS     = 12\n","TIMEOUT         = 60\n","RANDOM_STATE    = 42\n","TEST_FRAC       = 0.10   # ~10% by star\n","MIN_OBS         = 3      # keep short series to retain positives\n","BALANCE_RATIO   = 1.0    # undersample neg:pos ≈ 1.0 => 1:1\n","# =====================================================\n","\n","def make_session():\n","    s = requests.Session()\n","    s.headers.update({\"User-Agent\":\"RV-Pipeline/3.0\"})\n","    return s\n","\n","def stream_download(s, url, dest: Path):\n","    tmp = dest.with_suffix(dest.suffix+\".part\")\n","    with s.get(url, stream=True, timeout=TIMEOUT) as r:\n","        r.raise_for_status()\n","        with open(tmp,\"wb\") as f:\n","            for chunk in r.iter_content(1024*64):\n","                if chunk: f.write(chunk)\n","    tmp.replace(dest)\n","\n","# ---------------- 1) RADIAL (download + parse IPAC) ----------------\n","def fetch_radial(s):\n","    print(\"Fetching RADIAL wget script …\")\n","    bat = s.get(WGET_RADIAL_URL, timeout=TIMEOUT).text\n","    (RADIAL_DIR/\"wget_RADIAL.bat\").write_text(bat, encoding=\"utf-8\")\n","\n","    pairs = []\n","    for line in bat.splitlines():\n","        line = line.strip()\n","        if not line or line.lower().startswith((\"rem\",\"::\")): continue\n","        m = re.search(r'(https?://[^\\s\"\\']+)', line)\n","        if not m: continue\n","        url = m.group(1)\n","        if not re.search(r'\\.(tbl|csv|fits)(\\.gz)?$', url, re.I):  # keep only data\n","            continue\n","        m2 = re.search(r'-O\\s+(\"?)([^\"\\s]+)\\1', line)\n","        out_name = m2.group(2).strip() if m2 else None\n","        pairs.append((url, out_name))\n","    # dedupe\n","    seen = {}\n","    for u,n in pairs:\n","        if u not in seen or (seen[u] is None and n): seen[u]=n\n","    pairs = [(u, seen[u]) for u in seen]\n","\n","    tasks=[]\n","    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n","        for url, out_name in pairs:\n","            fname = out_name or url.rstrip(\"/\").split(\"/\")[-1].split(\"?\")[0]\n","            dest  = RADIAL_DIR/fname\n","            if dest.exists(): continue\n","            tasks.append(ex.submit(stream_download, s, url, dest))\n","        for i, fut in enumerate(as_completed(tasks),1):\n","            try: fut.result()\n","            except Exception: pass\n","            if i%25==0: print(f\"  … {i}/{len(tasks)} RADIAL files\")\n","    print(f\"RADIAL: have {len(list(RADIAL_DIR.glob('*.tbl')))} .tbl files.\")\n","\n","# robust IPAC column mapping\n","def _map_ipac_cols(df):\n","    cl = {c.lower().strip(): c for c in df.columns}\n","    def pick(cands):\n","        for k in cands:\n","            if k in cl: return cl[k]\n","        # fallback: contains\n","        for k in cl:\n","            if any(sub in k for sub in cands): return cl[k]\n","        return None\n","    time_col = pick(['bjd_tdb','bjd','time','jd','jd_utc','mjd'])\n","    rv_col   = pick(['rv','radial_velocity','vrad','mnvel','vel','velocity','v_r'])\n","    err_col  = pick(['rv_err','sigma_rv','e_rv','erv','rv_error','sig_rv','stdev','unc_rv'])\n","    return time_col, rv_col, err_col\n","\n","def read_radial_file(fp: Path):\n","    # IPAC reader first; fallback to whitespace\n","    try:\n","        tab = astro_ascii.read(str(fp), format='ipac', guess=True, fast_reader=False)\n","        df = tab.to_pandas()\n","    except Exception:\n","        try:\n","            df = pd.read_csv(fp, delim_whitespace=True, comment=\"#\")\n","        except Exception:\n","            return None\n","    if df.empty: return None\n","    tcol, rcol, ecol = _map_ipac_cols(df)\n","    if tcol is None or rcol is None:\n","        return None\n","    out = pd.DataFrame({\n","        \"time\": pd.to_numeric(df[tcol], errors=\"coerce\"),\n","        \"rv\":   pd.to_numeric(df[rcol], errors=\"coerce\"),\n","    })\n","    if ecol and ecol in df.columns:\n","        out[\"rv_err\"] = pd.to_numeric(df[ecol], errors=\"coerce\")\n","    else:\n","        out[\"rv_err\"] = np.nan\n","    out = out.dropna(subset=[\"time\",\"rv\"])\n","    if out.empty: return None\n","    # star_id from filename family (UID_xxx_RVC_###)\n","    m = re.match(r'^(.*)_RVC_', fp.stem)\n","    star_id = m.group(1) if m else fp.stem\n","    out[\"star_id\"] = star_id\n","    out[\"source\"]  = \"RADIAL\"\n","    out[\"label\"]   = 1\n","    return out\n","\n","def load_radial_ipac():\n","    fps = list(RADIAL_DIR.glob(\"*.tbl\"))\n","    if not fps: return pd.DataFrame(columns=[\"time\",\"rv\",\"rv_err\",\"star_id\",\"source\",\"label\"])\n","    rows=[]\n","    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n","        futs = {ex.submit(read_radial_file, fp): fp for fp in fps}\n","        for fut in as_completed(futs):\n","            df = fut.result()\n","            if df is not None: rows.append(df)\n","    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame(columns=[\"time\",\"rv\",\"rv_err\",\"star_id\",\"source\",\"label\"])\n","\n","# ---------------- 2) HARPS (download + parse) ----------------\n","def fetch_harps(s):\n","    existing = list(HARPS_DIR.glob(\"rvbank.dat\")) + list(HARPS_DIR.glob(\"rvbank.dat.gz\"))\n","    if existing:\n","        print(\"HARPS: file present:\", existing[0].name)\n","        return existing[0]\n","    for url in HARPS_URLS:\n","        try:\n","            print(\"Trying HARPS:\", url)\n","            dest = HARPS_DIR / url.split(\"/\")[-1]\n","            stream_download(s, url, dest)\n","            print(\"HARPS: downloaded\", dest.name)\n","            return dest\n","        except Exception:\n","            continue\n","    print(\"HARPS: download failed.\")\n","    return None\n","\n","def load_harps(rvbank_path: Path|None):\n","    if rvbank_path is None:\n","        return pd.DataFrame(columns=[\"time\",\"rv\",\"rv_err\",\"star_id\",\"source\"])\n","    if rvbank_path.suffix==\".gz\":\n","        with gzip.open(rvbank_path,\"rt\",encoding=\"utf-8\",errors=\"replace\") as f:\n","            text=f.read()\n","    else:\n","        text=rvbank_path.read_text(encoding=\"utf-8\",errors=\"replace\")\n","    rows=[]\n","    for ln in text.splitlines():\n","        if not ln or ln.startswith(\"#\"): continue\n","        parts = re.split(r\"\\s+\", ln.strip())\n","        if len(parts)<4: continue\n","        try:\n","            t=float(parts[1]); rv=float(parts[2]); er=float(parts[3])\n","        except:\n","            continue\n","        rows.append((t,rv,er,parts[0]))\n","    if not rows:\n","        return pd.DataFrame(columns=[\"time\",\"rv\",\"rv_err\",\"star_id\",\"source\"])\n","    df=pd.DataFrame(rows,columns=[\"time\",\"rv\",\"rv_err\",\"star_id\"])\n","    df[\"source\"]=\"HARPS\"\n","    return df\n","\n","def fetch_confirmed_hosts(s):\n","    try:\n","        csv = s.get(CONFIRMED_HOSTS_CSV, timeout=TIMEOUT).text\n","        df = pd.read_csv(io.StringIO(csv))\n","        df[\"hostname_norm\"]=df[\"hostname\"].astype(str).str.strip().str.lower()\n","        return set(df[\"hostname_norm\"].tolist())\n","    except Exception:\n","        print(\"WARN: failed to fetch confirmed host list; treating HARPS all as negatives.\")\n","        return set()\n","\n","def label_harps(df_harps, confirmed_set):\n","    if df_harps.empty: return df_harps\n","    df=df_harps.copy()\n","    df[\"label\"]=df[\"star_id\"].astype(str).str.strip().str.lower().isin(confirmed_set).astype(int)\n","    return df\n","\n","# ---------------- 3) Cleaning + series sanity ----------------\n","def clean_series(df, min_obs=MIN_OBS):\n","    if df.empty: return df\n","    keep=[\"time\",\"rv\",\"rv_err\",\"star_id\",\"source\",\"label\"]\n","    for c in keep:\n","        if c not in df.columns: df[c]=np.nan\n","    df=df[keep].copy()\n","    df[\"time\"]=pd.to_numeric(df[\"time\"], errors=\"coerce\")\n","    df[\"rv\"]=pd.to_numeric(df[\"rv\"], errors=\"coerce\")\n","    df[\"rv_err\"]=pd.to_numeric(df[\"rv_err\"], errors=\"coerce\")\n","    df=df.dropna(subset=[\"time\",\"rv\"])\n","    # require min_obs per star\n","    counts=df.groupby(\"star_id\")[\"time\"].count()\n","    good=counts[counts>=min_obs].index\n","    return df[df.star_id.isin(good)]\n","\n","# ---------------- 4) Features ----------------\n","def features_of_one(df):\n","    t=df[\"time\"].values.astype(float)\n","    y=df[\"rv\"].values.astype(float)\n","    if len(t)<3 or np.std(y)==0: return None\n","    # detrend-light: normalize\n","    y=(y-np.median(y))/(np.std(y)+1e-9)\n","\n","    try:\n","        freq,power=LombScargle(t,y).autopower()\n","        if len(freq)==0: return None\n","        idx=np.argsort(power)[-3:]  # top-3 peaks\n","        topf=freq[idx]; topp=power[idx]\n","        bestf=topf[-1]\n","        period = 1.0/bestf if bestf>0 else np.nan\n","        # sinusoid amplitude at bestf\n","        phi=2*np.pi*bestf*t\n","        A=np.vstack([np.sin(phi), np.cos(phi), np.ones_like(phi)]).T\n","        coef, *_ = np.linalg.lstsq(A, y, rcond=None)\n","        amp=float(np.sqrt(coef[0]**2+coef[1]**2))\n","        p1=float(topp[-1])\n","        p2=float(topp[-2]) if len(topp)>1 else 0.0\n","        p3=float(topp[-3]) if len(topp)>2 else 0.0\n","    except Exception:\n","        period=np.nan; amp=0.0; p1=p2=p3=0.0\n","\n","    return {\n","        \"period\": period,\n","        \"power1\": p1,\n","        \"power2\": p2,\n","        \"power3\": p3,\n","        \"amp\":    amp,\n","        \"rms\":    float(np.std(y)),\n","        \"mad\":    float(np.median(np.abs(y-np.median(y)))),\n","        \"skew\":   float(pd.Series(y).skew()),\n","        \"n_obs\":  int(len(y)),\n","        \"span_days\": float(t.max()-t.min()),\n","    }\n","\n","def build_feature_table(series_df):\n","    feats=[]\n","    for sid,g in series_df.groupby(\"star_id\", sort=False):\n","        f=features_of_one(g)\n","        if f is None: continue\n","        f[\"star_id\"]=sid\n","        f[\"label\"]=int(g[\"label\"].iloc[0])\n","        feats.append(f)\n","    return pd.DataFrame(feats)\n","\n","# ---------------- 5) Split (stratified by star) + balance ----------------\n","def stratified_group_split(feat_df, test_frac=TEST_FRAC, seed=RANDOM_STATE):\n","    X = feat_df.drop(columns=[\"label\",\"star_id\"])\n","    y = feat_df[\"label\"].values\n","    groups = feat_df[\"star_id\"].values\n","    n_splits = max(3, int(round(1/test_frac)))\n","    sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    train_idx, test_idx = next(sgkf.split(X, y, groups))\n","    train_df = feat_df.iloc[train_idx].copy()\n","    test_df  = feat_df.iloc[test_idx].copy()\n","    return train_df, test_df\n","\n","def make_balanced_train(train_df, ratio=BALANCE_RATIO, seed=RANDOM_STATE):\n","    pos = train_df[train_df.label==1]\n","    neg = train_df[train_df.label==0]\n","    if len(pos)==0: raise RuntimeError(\"No positives in training after split.\")\n","    need_neg = int(max(1, round(len(pos)*ratio)))\n","    neg_bal = neg.sample(n=min(need_neg, len(neg)), random_state=seed, replace=False)\n","    bal = pd.concat([pos, neg_bal], ignore_index=True).sample(frac=1.0, random_state=seed)\n","    return bal\n","\n","# ---------------- 6) Train + eval ----------------\n","def train_lightgbm(train_df, test_df, seed=RANDOM_STATE):\n","    features=[c for c in train_df.columns if c not in (\"star_id\",\"label\")]\n","    Xtr, ytr = train_df[features].values, train_df[\"label\"].values\n","    Xte, yte = test_df[features].values,  test_df[\"label\"].values\n","\n","    clf = lgb.LGBMClassifier(\n","        n_estimators=900, learning_rate=0.03, num_leaves=31,\n","        subsample=0.9, colsample_bytree=0.9,\n","        min_child_samples=20, random_state=seed\n","    )\n","    clf.fit(Xtr, ytr)\n","\n","    pred = clf.predict_proba(Xte)[:,1]\n","    auc = roc_auc_score(yte, pred)\n","    ap  = average_precision_score(yte, pred)\n","    print(f\"\\n=== Eval ===\\nAUC: {auc:.3f} | AP: {ap:.3f}\")\n","\n","    # choose threshold by best F1 on PR curve\n","    prec, rec, thr = precision_recall_curve(yte, pred)\n","    f1 = 2*prec*rec/(prec+rec+1e-9)\n","    best_idx = int(np.argmax(f1))\n","    best_thr = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n","    yhat = (pred>=best_thr).astype(int)\n","    print(f\"Best F1 thr ~ {best_thr:.3f} | P={float(prec[best_idx]):.3f} R={float(rec[best_idx]):.3f}\")\n","    print(\"\\nReport @bestF1:\\n\", classification_report(yte, yhat, digits=3))\n","\n","    fi = pd.DataFrame({\n","        \"feature\": features,\n","        \"gain\": clf.booster_.feature_importance(importance_type=\"gain\")\n","    }).sort_values(\"gain\", ascending=False)\n","    print(\"\\nTop features:\\n\", fi.head(10).to_string(index=False))\n","    return clf, fi, pred, best_thr\n","\n","# ========================== RUN ==========================\n","np.random.seed(RANDOM_STATE)\n","\n","with make_session() as s:\n","    # download\n","    fetch_radial(s)\n","    harps_path = fetch_harps(s)\n","    # load\n","    df_radial = load_radial_ipac()\n","    df_harps  = load_harps(harps_path)\n","    # label harps via confirmed hosts\n","    hosts = fetch_confirmed_hosts(s)\n","    df_harps = label_harps(df_harps, hosts)\n","\n","# clean & keep short series too (>= MIN_OBS)\n","df_radial = clean_series(df_radial, MIN_OBS)\n","df_harps  = clean_series(df_harps,  MIN_OBS)\n","\n","# merge (RADIAL positives + HARPS mixed)\n","df_all = pd.concat([df_radial, df_harps], ignore_index=True)\n","\n","# save series\n","PROC_DIR.mkdir(parents=True, exist_ok=True)\n","df_radial.to_parquet(PROC_DIR/\"radial_series.parquet\", index=False)\n","if not df_harps.empty: df_harps.to_parquet(PROC_DIR/\"harps_series.parquet\", index=False)\n","df_all.to_parquet(PROC_DIR/\"rv_series_merged.parquet\", index=False)\n","\n","# sanity log\n","print(\"\\nSeries rows by source:\")\n","print(df_all.groupby(\"source\").size())\n","print(\"\\nStar counts by label:\")\n","star_lab = df_all.groupby(\"star_id\")[\"label\"].first().value_counts()\n","print(star_lab)\n","\n","# features\n","feat_df = build_feature_table(df_all).dropna()\n","feat_df.to_parquet(PROC_DIR/\"rv_features.parquet\", index=False)\n","print(\"\\nFeature table shape:\", feat_df.shape)\n","print(\"Pos/Neg in features:\", feat_df[\"label\"].value_counts().to_dict())\n","\n","# split (stratified by star) and balance train\n","train_df, test_df = stratified_group_split(feat_df, TEST_FRAC, RANDOM_STATE)\n","print(f\"\\nSplit → Train stars: {train_df['star_id'].nunique()} | Test stars: {test_df['star_id'].nunique()}\")\n","print(\"Train pos/neg:\", train_df[\"label\"].sum(), \"/\", len(train_df)-train_df[\"label\"].sum())\n","print(\"Test  pos/neg:\", test_df[\"label\"].sum(),  \"/\", len(test_df)-test_df[\"label\"].sum())\n","\n","train_bal = make_balanced_train(train_df, ratio=BALANCE_RATIO, seed=RANDOM_STATE)\n","print(\"\\nBalanced train size:\", train_bal.shape, \"→ pos/neg:\",\n","      int(train_bal['label'].sum()), \"/\", int(len(train_bal)-train_bal['label'].sum()))\n","\n","# train\n","model, fi, pred, best_thr = train_lightgbm(train_bal, test_df)\n","\n","# save artifacts\n","(model.booster_).save_model(str(PROC_DIR/\"lightgbm_rv.txt\"))\n","fi.to_csv(PROC_DIR/\"feature_importances.csv\", index=False)\n","out = test_df[[\"star_id\",\"label\"]].copy()\n","out[\"pred_prob\"]=pred\n","out[\"pred_label_bestF1\"]=(pred>=best_thr).astype(int)\n","out.to_csv(PROC_DIR/\"test_predictions.csv\", index=False)\n","\n","print(\"\\n✅ Done. Artifacts:\")\n","print(\"  -\", PROC_DIR/\"radial_series.parquet\")\n","if not df_harps.empty: print(\"  -\", PROC_DIR/\"harps_series.parquet\")\n","print(\"  -\", PROC_DIR/\"rv_series_merged.parquet\")\n","print(\"  -\", PROC_DIR/\"rv_features.parquet\")\n","print(\"  -\", PROC_DIR/\"feature_importances.csv\")\n","print(\"  -\", PROC_DIR/\"lightgbm_rv.txt\")\n","print(\"  -\", PROC_DIR/\"test_predictions.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQas1ShMzy1y","executionInfo":{"status":"ok","timestamp":1759576346517,"user_tz":-180,"elapsed":190409,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"0806f002-13cc-426b-d967-819d5966b04b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fetching RADIAL wget script …\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: exoplanetarchive.ipac.caltech.edu. Connection pool size: 10\n","WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: exoplanetarchive.ipac.caltech.edu. Connection pool size: 10\n"]},{"output_type":"stream","name":"stdout","text":["  … 25/1071 RADIAL files\n","  … 50/1071 RADIAL files\n","  … 75/1071 RADIAL files\n","  … 100/1071 RADIAL files\n","  … 125/1071 RADIAL files\n","  … 150/1071 RADIAL files\n","  … 175/1071 RADIAL files\n","  … 200/1071 RADIAL files\n","  … 225/1071 RADIAL files\n","  … 250/1071 RADIAL files\n","  … 275/1071 RADIAL files\n","  … 300/1071 RADIAL files\n","  … 325/1071 RADIAL files\n","  … 350/1071 RADIAL files\n","  … 375/1071 RADIAL files\n","  … 400/1071 RADIAL files\n","  … 425/1071 RADIAL files\n","  … 450/1071 RADIAL files\n","  … 475/1071 RADIAL files\n","  … 500/1071 RADIAL files\n","  … 525/1071 RADIAL files\n","  … 550/1071 RADIAL files\n","  … 575/1071 RADIAL files\n","  … 600/1071 RADIAL files\n","  … 625/1071 RADIAL files\n","  … 650/1071 RADIAL files\n","  … 675/1071 RADIAL files\n","  … 700/1071 RADIAL files\n","  … 725/1071 RADIAL files\n","  … 750/1071 RADIAL files\n","  … 775/1071 RADIAL files\n","  … 800/1071 RADIAL files\n","  … 825/1071 RADIAL files\n","  … 850/1071 RADIAL files\n","  … 875/1071 RADIAL files\n","  … 900/1071 RADIAL files\n","  … 925/1071 RADIAL files\n","  … 950/1071 RADIAL files\n","  … 975/1071 RADIAL files\n","  … 1000/1071 RADIAL files\n","  … 1025/1071 RADIAL files\n","  … 1050/1071 RADIAL files\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: exoplanetarchive.ipac.caltech.edu. Connection pool size: 10\n","WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: exoplanetarchive.ipac.caltech.edu. Connection pool size: 10\n"]},{"output_type":"stream","name":"stdout","text":["RADIAL: have 1071 .tbl files.\n","Trying HARPS: https://cdsarc.cds.unistra.fr/ftp/J/A+A/636/A74/rvbank.dat.gz\n","HARPS: downloaded rvbank.dat.gz\n","\n","Series rows by source:\n","source\n","HARPS     212552\n","RADIAL     43540\n","dtype: int64\n","\n","Star counts by label:\n","label\n","0    2859\n","1     559\n","Name: count, dtype: int64\n","\n","Feature table shape: (3416, 12)\n","Pos/Neg in features: {0: 2857, 1: 559}\n","\n","Split → Train stars: 3074 | Test stars: 342\n","Train pos/neg: 503 / 2571\n","Test  pos/neg: 56 / 286\n","\n","Balanced train size: (1006, 12) → pos/neg: 503 / 503\n","[LightGBM] [Info] Number of positive: 503, number of negative: 503\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000208 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 2433\n","[LightGBM] [Info] Number of data points in the train set: 1006, number of used features: 10\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","\n","=== Eval ===\n","AUC: 0.935 | AP: 0.783\n","Best F1 thr ~ 0.984 | P=0.710 R=0.786\n","\n","Report @bestF1:\n","               precision    recall  f1-score   support\n","\n","           0      0.957     0.937     0.947       286\n","           1      0.710     0.786     0.746        56\n","\n","    accuracy                          0.912       342\n","   macro avg      0.833     0.861     0.846       342\n","weighted avg      0.917     0.912     0.914       342\n","\n","\n","Top features:\n","   feature        gain\n","      rms 5654.502221\n","span_days 4358.552284\n","    n_obs 3240.377429\n","   period 2483.441178\n","     skew 1796.983962\n","      mad 1632.752034\n","      amp 1513.825165\n","   power3 1491.527922\n","   power1  927.017931\n","   power2  489.925754\n","\n","✅ Done. Artifacts:\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/radial_series.parquet\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/harps_series.parquet\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/rv_series_merged.parquet\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/rv_features.parquet\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/feature_importances.csv\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/lightgbm_rv.txt\n","  - /content/drive/MyDrive/nasa_exoplanet/processed/test_predictions.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","PROC_DIR = Path(\"/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity/processed\")\n","\n","series = pd.read_parquet(PROC_DIR/\"rv_series_merged.parquet\")\n","print(series.groupby([\"source\"]).size().sort_values(ascending=False).head(10))\n","print(series.groupby([\"source\",\"star_id\"]).size().describe())\n","\n","# After feature build:\n","feat = pd.read_parquet(PROC_DIR/\"rv_features.parquet\")\n","print(feat.groupby(\"label\").size())\n","print(feat.groupby([\"label\"]).size(), \" total:\", len(feat))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2ZA9OeJ4s9i","executionInfo":{"status":"ok","timestamp":1759575726775,"user_tz":-180,"elapsed":102,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"a0650615-1b76-4cf4-c3f3-a35916a152dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["source\n","HARPS     209324\n","RADIAL        16\n","dtype: int64\n","count     2316.000000\n","mean        90.388601\n","std        510.448358\n","min          8.000000\n","25%         12.000000\n","50%         25.000000\n","75%         51.000000\n","max      15490.000000\n","dtype: float64\n","label\n","0    2269\n","1      45\n","dtype: int64\n","label\n","0    2269\n","1      45\n","dtype: int64  total: 2314\n"]}]},{"cell_type":"code","source":["#how to use"],"metadata":{"id":"8uMEEANa4s_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rv_infer_standalone.py\n","# Standalone inference helpers for your RV model.\n","# - predict_from_arrays(model_path, time, rv, rv_err=None, threshold=0.5)\n","# - predict_from_files(model_path, file_paths, threshold=0.5)\n","#\n","# File parsing supports: IPAC .tbl (Astropy), CSV, or whitespace-separated text.\n","\n","import sys, subprocess, io, re, warnings\n","from pathlib import Path\n","\n","def _pip_install(pkgs):\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# Deps (install if missing)\n","try:\n","    import numpy as np\n","    import pandas as pd\n","except Exception:\n","    _pip_install([\"numpy\", \"pandas\"])\n","    import numpy as np\n","    import pandas as pd\n","\n","try:\n","    import lightgbm as lgb\n","except Exception:\n","    _pip_install([\"lightgbm\"])\n","    import lightgbm as lgb\n","\n","try:\n","    from astropy.io import ascii as astro_ascii\n","    from astropy.timeseries import LombScargle\n","except Exception:\n","    _pip_install([\"astropy\"])\n","    from astropy.io import ascii as astro_ascii\n","    from astropy.timeseries import LombScargle\n","\n","\n","# ==== config: must match training features ====\n","FEATURE_COLS = [\n","    \"period\",\"power1\",\"power2\",\"power3\",\"amp\",\n","    \"rms\",\"mad\",\"skew\",\"n_obs\",\"span_days\"\n","]\n","\n","\n","# ---------- core utils ----------\n","def load_model(model_path: str | Path) -> lgb.Booster:\n","    model_path = Path(model_path)\n","    if not model_path.exists():\n","        raise FileNotFoundError(f\"Model not found: {model_path}\")\n","    return lgb.Booster(model_file=str(model_path))\n","\n","def _features_from_series(time: np.ndarray, rv: np.ndarray, rv_err: np.ndarray | None = None):\n","    \"\"\"Build the same features as training from a single star's RV curve.\"\"\"\n","    t = np.asarray(time, dtype=float)\n","    y = np.asarray(rv, dtype=float)\n","    if len(t) < 3 or np.std(y) == 0 or np.any(~np.isfinite(t)) or np.any(~np.isfinite(y)):\n","        return None\n","\n","    # normalize like training\n","    y = (y - np.median(y)) / (np.std(y) + 1e-9)\n","\n","    # Lomb–Scargle periodogram (unweighted to mirror training)\n","    try:\n","        freq, power = LombScargle(t, y).autopower()\n","    except Exception:\n","        return None\n","    if len(freq) == 0:\n","        return None\n","\n","    idx = np.argsort(power)[-3:]\n","    topf = freq[idx]; topp = power[idx]\n","    bestf = topf[-1]\n","    period = 1.0 / bestf if bestf > 0 else np.nan\n","\n","    # sinusoid amplitude at bestf (least squares)\n","    phi = 2 * np.pi * bestf * t\n","    A = np.vstack([np.sin(phi), np.cos(phi), np.ones_like(phi)]).T\n","    coef, *_ = np.linalg.lstsq(A, y, rcond=None)\n","    amp = float(np.sqrt(coef[0]**2 + coef[1]**2))\n","\n","    feats = {\n","        \"period\": float(period),\n","        \"power1\": float(topp[-1]),\n","        \"power2\": float(topp[-2]) if len(topp) > 1 else 0.0,\n","        \"power3\": float(topp[-3]) if len(topp) > 2 else 0.0,\n","        \"amp\":    amp,\n","        \"rms\":    float(np.std(y)),\n","        \"mad\":    float(np.median(np.abs(y - np.median(y)))),\n","        \"skew\":   float(pd.Series(y).skew()),\n","        \"n_obs\":  int(len(y)),\n","        \"span_days\": float(np.max(t) - np.min(t)),\n","    }\n","    return feats\n","\n","def _map_cols(df: pd.DataFrame):\n","    \"\"\"Find time/rv/rv_err column names in arbitrary tables.\"\"\"\n","    cl = {c.lower().strip(): c for c in df.columns}\n","    def pick(cands):\n","        for k in cands:\n","            if k in cl: return cl[k]\n","        for k in cl:\n","            if any(sub in k for sub in cands): return cl[k]\n","        return None\n","    tcol = pick(['bjd_tdb','bjd','time','jd','jd_utc','mjd','date'])\n","    rcol = pick(['rv','radial_velocity','vrad','mnvel','vel','velocity','v_r'])\n","    ecol = pick(['rv_err','sigma_rv','e_rv','erv','rv_error','sig_rv','stdev','unc_rv'])\n","    return tcol, rcol, ecol\n","\n","def _read_one_file(path: str | Path) -> tuple[pd.DataFrame, str]:\n","    \"\"\"\n","    Read one RV file: IPAC .tbl preferred, else CSV, else whitespace.\n","    Returns (df, star_id_guess). df has columns [time, rv, rv_err].\n","    \"\"\"\n","    fp = Path(path)\n","    if not fp.exists():\n","        raise FileNotFoundError(f\"File not found: {fp}\")\n","\n","    data = None\n","    name = fp.name.lower()\n","\n","    # IPAC first for .tbl\n","    if name.endswith(\".tbl\"):\n","        try:\n","            tab = astro_ascii.read(str(fp), format=\"ipac\", guess=True, fast_reader=False)\n","            data = tab.to_pandas()\n","        except Exception:\n","            data = None\n","\n","    # CSV fallback\n","    if data is None:\n","        try:\n","            data = pd.read_csv(fp)\n","        except Exception:\n","            # whitespace fallback\n","            data = pd.read_csv(fp, delim_whitespace=True, comment=\"#\")\n","\n","    if data is None or data.empty:\n","        raise ValueError(f\"Could not parse any rows from: {fp}\")\n","\n","    tcol, rcol, ecol = _map_cols(data)\n","    if tcol is None or rcol is None:\n","        raise ValueError(f\"Could not find time/rv columns in: {fp}\")\n","\n","    df = pd.DataFrame({\n","        \"time\": pd.to_numeric(data[tcol], errors=\"coerce\"),\n","        \"rv\":   pd.to_numeric(data[rcol], errors=\"coerce\"),\n","    })\n","    if ecol and ecol in data.columns:\n","        df[\"rv_err\"] = pd.to_numeric(data[ecol], errors=\"coerce\")\n","    else:\n","        df[\"rv_err\"] = np.nan\n","\n","    df = df.dropna(subset=[\"time\",\"rv\"]).sort_values(\"time\")\n","    if len(df) < 3:\n","        raise ValueError(f\"Need at least 3 valid (time, rv) points in: {fp}\")\n","\n","    # star_id guess from filename like UID_xxx_RVC_###.tbl\n","    m = re.match(r'^(.*)_RVC_', fp.stem, flags=re.IGNORECASE)\n","    star_id = m.group(1) if m else fp.stem\n","    return df, star_id\n","\n","\n","# ---------- public API ----------\n","def predict_from_arrays(model_path: str | Path,\n","                        time, rv, rv_err=None,\n","                        threshold: float = 0.5) -> dict:\n","    \"\"\"\n","    Predict from raw arrays (one star).\n","    Returns dict with prob, label, features, n_obs, span_days.\n","    \"\"\"\n","    booster = load_model(model_path)\n","    time = np.asarray(time, dtype=float)\n","    rv   = np.asarray(rv,   dtype=float)\n","    if rv_err is None:\n","        rv_err = np.full_like(rv, np.nan, dtype=float)\n","    else:\n","        rv_err = np.asarray(rv_err, dtype=float)\n","\n","    feats = _features_from_series(time, rv, rv_err)\n","    if feats is None:\n","        return {\"ok\": False, \"msg\": \"Not enough signal/points to compute features (need ≥3 and non-zero std).\"}\n","\n","    X = pd.DataFrame([feats])[FEATURE_COLS]\n","    prob = float(booster.predict(X)[0])\n","    pred = int(prob >= float(threshold))\n","    return {\n","        \"ok\": True,\n","        \"probability\": prob,\n","        \"pred_label\": pred,   # 1=planet, 0=not\n","        \"threshold\": float(threshold),\n","        \"features\": feats,\n","        \"n_obs\": int(feats[\"n_obs\"]),\n","        \"span_days\": float(feats[\"span_days\"]),\n","    }\n","\n","def predict_from_files(model_path: str | Path,\n","                       file_paths: list[str | Path],\n","                       threshold: float = 0.5) -> pd.DataFrame:\n","    \"\"\"\n","    Predict for one or many files. Returns a DataFrame with:\n","    [file, star_id, prob, pred_label, n_obs, span_days, error]\n","    \"\"\"\n","    booster = load_model(model_path)\n","    rows = []\n","    for path in file_paths:\n","        rec = {\"file\": str(path), \"star_id\": None,\n","               \"prob\": np.nan, \"pred_label\": np.nan,\n","               \"n_obs\": np.nan, \"span_days\": np.nan,\n","               \"error\": \"\"}\n","        try:\n","            df, sid = _read_one_file(path)\n","            rec[\"star_id\"] = sid\n","            feats = _features_from_series(df[\"time\"].values, df[\"rv\"].values, df[\"rv_err\"].values)\n","            if feats is None:\n","                rec[\"error\"] = \"insufficient data / zero variance\"\n","            else:\n","                X = pd.DataFrame([feats])[FEATURE_COLS]\n","                prob = float(booster.predict(X)[0])\n","                rec[\"prob\"] = prob\n","                rec[\"pred_label\"] = int(prob >= float(threshold))\n","                rec[\"n_obs\"] = int(feats[\"n_obs\"])\n","                rec[\"span_days\"] = float(feats[\"span_days\"])\n","        except Exception as e:\n","            rec[\"error\"] = str(e)\n","        rows.append(rec)\n","\n","    out = pd.DataFrame(rows)\n","    return out\n","\n","\n","# ---------- example usage (optional) ----------\n","if __name__ == \"__main__\":\n","    # Example 1: arrays input\n","    # Replace with your own quick test arrays\n","    t = [2450000.0, 2450020.0, 2450100.0, 2450300.0, 2450500.0]\n","    v = [10.2, -5.0, 15.1, -8.2, 12.3]\n","    res = predict_from_arrays(\n","        model_path=\"/content/drive/MyDrive/nasa_exoplanet/processed/lightgbm_rv.txt\",\n","        time=t, rv=v, rv_err=None, threshold=0.5  # or 0.984 if that's your chosen cutoff\n","    )\n","    print(\"arrays inference →\", res)\n","\n","    # Example 2: files input (supports multiple files)\n","    # Replace these with actual paths to your .tbl/.csv\n","    files = [\n","        \"/content/drive/MyDrive/nasa_exoplanet/RADIAL_raw/UID_0000522_RVC_001.tbl\",\n","        \"/content/drive/MyDrive/nasa_exoplanet/RADIAL_raw/UID_0000522_RVC_002.tbl\",\n","    ]\n","    df_preds = predict_from_files(\n","        model_path=\"/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity/processed/lightgbm_rv.txt\",\n","        file_paths=files,\n","        threshold=0.5  # or your picked threshold, e.g., 0.984\n","    )\n","    print(df_preds)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkuDNtlU4tCL","executionInfo":{"status":"ok","timestamp":1759579060379,"user_tz":-180,"elapsed":121,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"dc8efa67-feaa-41d7-f819-e7fe3fb23854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["arrays inference → {'ok': True, 'probability': 2.950631051185226e-07, 'pred_label': 0, 'threshold': 0.5, 'features': {'period': 135.13513513513513, 'power1': 0.9939665207495667, 'power2': 0.9856172793291845, 'power3': 0.9814772392200638, 'amp': 1.567861280102445, 'rms': 0.9999999998953448, 'mad': 0.512810472683866, 'skew': -0.5384892867104116, 'n_obs': 5, 'span_days': 500.0}, 'n_obs': 5, 'span_days': 500.0}\n","                                                file      star_id      prob  \\\n","0  /content/drive/MyDrive/nasa_exoplanet/RADIAL_r...  UID_0000522  0.299377   \n","1  /content/drive/MyDrive/nasa_exoplanet/RADIAL_r...  UID_0000522  0.999761   \n","\n","   pred_label  n_obs    span_days error  \n","0           0     53  2801.237949        \n","1           1     27  1359.044500        \n"]}]},{"cell_type":"code","source":["\n","model_path = \"/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity/processed/lightgbm_rv.txt\"\n","# define your own arrays\n","T_array   = [2450000.0, 2450020.0, 2450100.0, 2450300.0, 2450500.0]\n","RV_array  = [10.2, -5.0, 15.1, -8.2, 12.3]\n","ERR_array = [1.5, 1.2, 1.0, 1.3, 1.1]  # optional; can be None\n","\n","res = predict_from_arrays(\n","    model_path=model_path,\n","    time=T_array, rv=RV_array, rv_err=ERR_array,\n","    threshold=0.984  # use the threshold you liked\n",")\n","print(res)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuplp1avFdo6","executionInfo":{"status":"ok","timestamp":1759579244455,"user_tz":-180,"elapsed":55,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"cc791d6a-edc4-4d68-d9f1-8e4a716484f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ok': True, 'probability': 2.950631051185226e-07, 'pred_label': 0, 'threshold': 0.984, 'features': {'period': 135.13513513513513, 'power1': 0.9939665207495667, 'power2': 0.9856172793291845, 'power3': 0.9814772392200638, 'amp': 1.567861280102445, 'rms': 0.9999999998953448, 'mad': 0.512810472683866, 'skew': -0.5384892867104116, 'n_obs': 5, 'span_days': 500.0}, 'n_obs': 5, 'span_days': 500.0}\n"]}]},{"cell_type":"code","source":["\n","model_path = \"/content/drive/MyDrive/nasa_exoplanet/Radial-Velocity/processed/lightgbm_rv.txt\"\n","path = \"/content/drive/MyDrive/nasa_exoplanet/RADIAL_raw/UID_0000522_RVC_001.tbl\"\n","\n","df, star_id = _read_one_file(path)   # parses IPAC .tbl / csv / whitespace\n","res = predict_from_arrays(\n","    model_path=model_path,\n","    time=df[\"time\"], rv=df[\"rv\"], rv_err=df[\"rv_err\"],\n","    threshold=0.984\n",")\n","print(star_id, res)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wd3j_sq0FgqZ","executionInfo":{"status":"ok","timestamp":1759579259841,"user_tz":-180,"elapsed":52,"user":{"displayName":"Kuzey Torlak","userId":"13838735001635341562"}},"outputId":"ae032f8e-398b-4f7a-bb70-56a19a538708"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["UID_0000522 {'ok': True, 'probability': 0.2993767721896214, 'pred_label': 0, 'threshold': 0.984, 'features': {'period': 28012.379489997402, 'power1': 0.5554498514772406, 'power2': 0.5516828204002343, 'power3': 0.5396734479828982, 'amp': 23.573162267889586, 'rms': 0.9999999999648725, 'mad': 0.6252664049935912, 'skew': -0.21970752994827183, 'n_obs': 53, 'span_days': 2801.23794899974}, 'n_obs': 53, 'span_days': 2801.23794899974}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Zdvzcl4vGLVi"},"execution_count":null,"outputs":[]}]}